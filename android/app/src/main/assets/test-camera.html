<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Camera Polyfill Test Page</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            padding: 20px;
            background: #f5f5f5;
        }
        .test-section {
            background: white;
            margin: 20px 0;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .test-result {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }
        .success { background: #e8f5e8; color: #2e7d2e; }
        .error { background: #ffe8e8; color: #d32f2f; }
        .info { background: #e8f4fd; color: #1976d2; }
        button {
            background: #1976d2;
            color: white;
            border: none;
            padding: 10px 20px;
            margin: 5px;
            border-radius: 4px;
            cursor: pointer;
        }
        button:hover { background: #1565c0; }
        button:disabled { background: #ccc; cursor: not-allowed; }
        .log {
            background: #f8f8f8;
            border: 1px solid #ddd;
            padding: 10px;
            margin: 10px 0;
            border-radius: 4px;
            font-family: monospace;
            font-size: 12px;
            max-height: 200px;
            overflow-y: auto;
        }
        .video-container {
            margin: 20px 0;
            text-align: center;
        }
        video {
            max-width: 100%;
            height: auto;
            border: 2px solid #ddd;
            border-radius: 8px;
        }
        .capture-preview {
            margin: 20px 0;
            text-align: center;
        }
        .capture-preview img {
            max-width: 100%;
            height: auto;
            border: 2px solid #ddd;
            border-radius: 8px;
        }
    </style>
</head>
<body>
    <h1>ðŸ“· Camera Polyfill Test Suite</h1>
    <p>Testing getUserMedia and camera polyfills with secure Android bridges.</p>

    <!-- Device Enumeration Tests -->
    <div class="test-section">
        <h2>ðŸ“± Device Enumeration Tests</h2>
        <div id="device-status" class="test-result info">Ready to test...</div>

        <button onclick="testEnumerateDevices()">Enumerate Camera Devices</button>
        <button onclick="testGetCapabilities()">Test Device Capabilities</button>

        <div id="device-log" class="log"></div>
    </div>

    <!-- Camera Access Tests -->
    <div class="test-section">
        <h2>ðŸŽ¥ Camera Access Tests</h2>
        <div id="camera-status" class="test-result info">Ready to test...</div>

        <button onclick="testGetUserMedia()">Request Camera (Back)</button>
        <button onclick="testGetUserMediaFront()">Request Camera (Front)</button>
        <button onclick="testGetUserMediaConstraints()">Test with Constraints</button>
        <button onclick="stopCurrentStream()">Stop Camera Stream</button>

        <div class="video-container">
            <video id="camera-video" autoplay muted playsinline style="display: none;"></video>
        </div>

        <div id="camera-log" class="log"></div>
    </div>

    <!-- Stream Management Tests -->
    <div class="test-section">
        <h2>ðŸ”„ Stream Management Tests</h2>
        <div id="stream-status" class="test-result info">Ready to test...</div>

        <button onclick="testStreamProperties()">Test Stream Properties</button>
        <button onclick="testTrackManagement()">Test Track Management</button>
        <button onclick="testStreamEvents()">Test Stream Events</button>
        <button onclick="testTrackConstraints()">Test Track Constraints</button>

        <div id="stream-log" class="log"></div>
    </div>

    <!-- Frame Capture Tests -->
    <div class="test-section">
        <h2>ðŸ“¸ Frame Capture Tests</h2>
        <div id="capture-status" class="test-result info">Ready to test...</div>

        <button onclick="testFrameCapture()">Capture Still Frame</button>
        <button onclick="testImageCapture()">Test ImageCapture API</button>

        <div class="capture-preview" id="capture-preview" style="display: none;">
            <h3>Captured Frame:</h3>
            <img id="captured-image" src="" alt="Captured frame">
        </div>

        <div id="capture-log" class="log"></div>
    </div>

    <!-- Bridge Status -->
    <div class="test-section">
        <h2>ðŸŒ‰ Bridge Status</h2>
        <div id="bridge-status"></div>
    </div>

    <script>
        // Global variables
        let currentStream = null;
        let currentTrack = null;

        // Logging utilities
        function log(section, message, type = 'info') {
            const logElement = document.getElementById(section + '-log');
            const timestamp = new Date().toLocaleTimeString();
            logElement.innerHTML += `<div>[${timestamp}] ${message}</div>`;
            logElement.scrollTop = logElement.scrollHeight;
            console.log(`[${section}] ${message}`);
        }

        function setStatus(section, message, type = 'info') {
            const statusElement = document.getElementById(section + '-status');
            statusElement.textContent = message;
            statusElement.className = `test-result ${type}`;
        }

        // Device Enumeration Tests
        async function testEnumerateDevices() {
            setStatus('device', 'Enumerating devices...', 'info');
            log('device', 'Starting device enumeration test');

            try {
                if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
                    throw new Error('mediaDevices.enumerateDevices not available');
                }

                const devices = await navigator.mediaDevices.enumerateDevices();
                log('device', `âœ“ Found ${devices.length} total devices`);

                const videoDevices = devices.filter(device => device.kind === 'videoinput');
                log('device', `âœ“ Found ${videoDevices.length} camera devices`);

                videoDevices.forEach((device, index) => {
                    log('device', `  Camera ${index + 1}: ${device.label || 'Unnamed'} (ID: ${device.deviceId})`);
                });

                setStatus('device', `Found ${videoDevices.length} camera devices`, 'success');

            } catch (error) {
                log('device', `âœ— Device enumeration failed: ${error.message}`, 'error');
                setStatus('device', 'Device enumeration failed!', 'error');
            }
        }

        async function testGetCapabilities() {
            log('device', 'Testing device capabilities');

            try {
                const devices = await navigator.mediaDevices.enumerateDevices();
                const videoDevices = devices.filter(device => device.kind === 'videoinput');

                if (videoDevices.length === 0) {
                    throw new Error('No camera devices found');
                }

                // Test capabilities for first camera
                const device = videoDevices[0];
                if (window.CameraBridge && window.CameraBridge.getCapabilities) {
                    const capabilities = window.CameraBridge.getCapabilities(device.deviceId);
                    const caps = JSON.parse(capabilities);

                    log('device', `âœ“ Capabilities for ${device.label}:`);
                    log('device', `  Facing mode: ${caps.facingMode}`);
                    log('device', `  Width range: ${caps.width.length} options`);
                    log('device', `  Height range: ${caps.height.length} options`);
                } else {
                    log('device', 'âš  getCapabilities not available through bridge');
                }

            } catch (error) {
                log('device', `âœ— Capabilities test failed: ${error.message}`, 'error');
            }
        }

        // Camera Access Tests
        async function testGetUserMedia() {
            setStatus('camera', 'Requesting camera access...', 'info');
            log('camera', 'Starting getUserMedia test (back camera)');

            try {
                const constraints = {
                    video: {
                        facingMode: 'environment',
                        width: { ideal: 1280 },
                        height: { ideal: 720 }
                    }
                };

                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                log('camera', `âœ“ Camera stream created: ${stream.id}`);

                currentStream = stream;
                currentTrack = stream.getVideoTracks()[0];

                // Display video
                const video = document.getElementById('camera-video');
                video.srcObject = stream;
                video.style.display = 'block';

                log('camera', `âœ“ Video element connected to stream`);
                log('camera', `âœ“ Video track: ${currentTrack.label} (${currentTrack.kind})`);

                setStatus('camera', 'Camera access successful!', 'success');

            } catch (error) {
                log('camera', `âœ— getUserMedia failed: ${error.message}`, 'error');
                setStatus('camera', 'Camera access failed!', 'error');
            }
        }

        async function testGetUserMediaFront() {
            setStatus('camera', 'Requesting front camera...', 'info');
            log('camera', 'Starting getUserMedia test (front camera)');

            try {
                const constraints = {
                    video: {
                        facingMode: 'user'
                    }
                };

                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                log('camera', `âœ“ Front camera stream created: ${stream.id}`);

                currentStream = stream;
                currentTrack = stream.getVideoTracks()[0];

                const video = document.getElementById('camera-video');
                video.srcObject = stream;
                video.style.display = 'block';

                setStatus('camera', 'Front camera access successful!', 'success');

            } catch (error) {
                log('camera', `âœ— Front camera failed: ${error.message}`, 'error');
                setStatus('camera', 'Front camera access failed!', 'error');
            }
        }

        async function testGetUserMediaConstraints() {
            log('camera', 'Testing getUserMedia with various constraints');

            try {
                const constraints = {
                    video: {
                        width: { min: 640, ideal: 1280, max: 1920 },
                        height: { min: 480, ideal: 720, max: 1080 },
                        frameRate: { ideal: 30 }
                    }
                };

                const stream = await navigator.mediaDevices.getUserMedia(constraints);
                log('camera', `âœ“ Constrained stream created: ${stream.id}`);

                currentStream = stream;
                currentTrack = stream.getVideoTracks()[0];

                // Test track settings
                if (currentTrack.getSettings) {
                    const settings = currentTrack.getSettings();
                    log('camera', `âœ“ Track settings: ${settings.width}x${settings.height} @ ${settings.frameRate}fps`);
                }

                const video = document.getElementById('camera-video');
                video.srcObject = stream;
                video.style.display = 'block';

            } catch (error) {
                log('camera', `âœ— Constrained getUserMedia failed: ${error.message}`, 'error');
            }
        }

        function stopCurrentStream() {
            log('camera', 'Stopping current camera stream');

            try {
                if (currentStream) {
                    currentStream.getTracks().forEach(track => {
                        track.stop();
                        log('camera', `âœ“ Stopped track: ${track.kind}`);
                    });

                    const video = document.getElementById('camera-video');
                    video.srcObject = null;
                    video.style.display = 'none';

                    currentStream = null;
                    currentTrack = null;

                    log('camera', 'âœ“ Camera stream stopped');
                    setStatus('camera', 'Camera stopped', 'info');
                } else {
                    log('camera', 'âš  No active stream to stop');
                }

            } catch (error) {
                log('camera', `âœ— Failed to stop stream: ${error.message}`, 'error');
            }
        }

        // Stream Management Tests
        function testStreamProperties() {
            log('stream', 'Testing stream properties');

            try {
                if (!currentStream) {
                    throw new Error('No active stream. Start camera first.');
                }

                log('stream', `âœ“ Stream ID: ${currentStream.id}`);
                log('stream', `âœ“ Stream active: ${currentStream.active}`);
                log('stream', `âœ“ Video tracks: ${currentStream.getVideoTracks().length}`);
                log('stream', `âœ“ Audio tracks: ${currentStream.getAudioTracks().length}`);
                log('stream', `âœ“ Total tracks: ${currentStream.getTracks().length}`);

                currentStream.getVideoTracks().forEach((track, index) => {
                    log('stream', `  Video track ${index}: ${track.label} (enabled: ${track.enabled})`);
                });

                setStatus('stream', 'Stream properties test passed!', 'success');

            } catch (error) {
                log('stream', `âœ— Stream properties test failed: ${error.message}`, 'error');
                setStatus('stream', 'Stream properties test failed!', 'error');
            }
        }

        function testTrackManagement() {
            log('stream', 'Testing track management');

            try {
                if (!currentTrack) {
                    throw new Error('No active track. Start camera first.');
                }

                log('stream', `âœ“ Track ID: ${currentTrack.id}`);
                log('stream', `âœ“ Track kind: ${currentTrack.kind}`);
                log('stream', `âœ“ Track label: ${currentTrack.label}`);
                log('stream', `âœ“ Track readyState: ${currentTrack.readyState}`);
                log('stream', `âœ“ Track enabled: ${currentTrack.enabled}`);
                log('stream', `âœ“ Track muted: ${currentTrack.muted}`);

                // Test enable/disable
                const originalEnabled = currentTrack.enabled;
                currentTrack.enabled = false;
                log('stream', `âœ“ Track disabled: ${currentTrack.enabled}`);
                currentTrack.enabled = originalEnabled;
                log('stream', `âœ“ Track re-enabled: ${currentTrack.enabled}`);

                setStatus('stream', 'Track management test passed!', 'success');

            } catch (error) {
                log('stream', `âœ— Track management test failed: ${error.message}`, 'error');
                setStatus('stream', 'Track management test failed!', 'error');
            }
        }

        function testStreamEvents() {
            log('stream', 'Testing stream events');

            try {
                if (!currentStream) {
                    throw new Error('No active stream. Start camera first.');
                }

                // Add event listeners
                currentStream.addEventListener('addtrack', (event) => {
                    log('stream', `âœ“ addtrack event: ${event.track.kind}`);
                });

                currentStream.addEventListener('removetrack', (event) => {
                    log('stream', `âœ“ removetrack event: ${event.track.kind}`);
                });

                if (currentTrack) {
                    currentTrack.addEventListener('ended', (event) => {
                        log('stream', `âœ“ track ended event`);
                    });

                    currentTrack.addEventListener('mute', (event) => {
                        log('stream', `âœ“ track mute event`);
                    });

                    currentTrack.addEventListener('unmute', (event) => {
                        log('stream', `âœ“ track unmute event`);
                    });
                }

                log('stream', 'âœ“ Event listeners attached');
                setStatus('stream', 'Stream events test setup complete!', 'success');

            } catch (error) {
                log('stream', `âœ— Stream events test failed: ${error.message}`, 'error');
                setStatus('stream', 'Stream events test failed!', 'error');
            }
        }

        async function testTrackConstraints() {
            log('stream', 'Testing track constraints');

            try {
                if (!currentTrack) {
                    throw new Error('No active track. Start camera first.');
                }

                // Test getConstraints
                if (currentTrack.getConstraints) {
                    const constraints = currentTrack.getConstraints();
                    log('stream', `âœ“ Current constraints: ${JSON.stringify(constraints)}`);
                }

                // Test getSettings
                if (currentTrack.getSettings) {
                    const settings = currentTrack.getSettings();
                    log('stream', `âœ“ Current settings: ${JSON.stringify(settings)}`);
                }

                // Test getCapabilities
                if (currentTrack.getCapabilities) {
                    const capabilities = currentTrack.getCapabilities();
                    log('stream', `âœ“ Track capabilities available`);
                }

                // Test applyConstraints
                if (currentTrack.applyConstraints) {
                    await currentTrack.applyConstraints({
                        width: { ideal: 640 },
                        height: { ideal: 480 }
                    });
                    log('stream', `âœ“ Constraints applied successfully`);
                }

                setStatus('stream', 'Track constraints test passed!', 'success');

            } catch (error) {
                log('stream', `âœ— Track constraints test failed: ${error.message}`, 'error');
                setStatus('stream', 'Track constraints test failed!', 'error');
            }
        }

        // Frame Capture Tests
        function testFrameCapture() {
            setStatus('capture', 'Testing frame capture...', 'info');
            log('capture', 'Starting frame capture test');

            try {
                if (!currentStream) {
                    throw new Error('No active stream. Start camera first.');
                }

                if (!window.CameraBridge || !window.CameraBridge.captureFrame) {
                    throw new Error('CameraBridge.captureFrame not available');
                }

                // Set up frame capture event listener
                currentStream.addEventListener('framecaptured', (event) => {
                    log('capture', `âœ“ Frame captured: ${event.detail.timestamp}`);

                    const preview = document.getElementById('capture-preview');
                    const image = document.getElementById('captured-image');

                    image.src = 'data:image/jpeg;base64,' + event.detail.imageData;
                    preview.style.display = 'block';

                    setStatus('capture', 'Frame captured successfully!', 'success');
                });

                // Trigger capture
                const result = window.CameraBridge.captureFrame(currentStream.id);
                const response = JSON.parse(result);

                if (response.message && response.message.includes('error')) {
                    throw new Error(response.message);
                }

                log('capture', 'âœ“ Frame capture initiated');

            } catch (error) {
                log('capture', `âœ— Frame capture failed: ${error.message}`, 'error');
                setStatus('capture', 'Frame capture failed!', 'error');
            }
        }

        function testImageCapture() {
            log('capture', 'Testing ImageCapture API compatibility');

            try {
                if (!currentTrack) {
                    throw new Error('No active track. Start camera first.');
                }

                if (window.ImageCapture) {
                    const imageCapture = new ImageCapture(currentTrack);
                    log('capture', 'âœ“ ImageCapture instance created');

                    if (imageCapture.getPhotoCapabilities) {
                        imageCapture.getPhotoCapabilities().then(capabilities => {
                            log('capture', 'âœ“ Photo capabilities retrieved');
                        });
                    }

                    if (imageCapture.takePhoto) {
                        log('capture', 'âœ“ takePhoto method available');
                    }

                } else {
                    log('capture', 'âš  ImageCapture API not available (not implemented in polyfill)');
                }

            } catch (error) {
                log('capture', `âœ— ImageCapture test failed: ${error.message}`, 'error');
            }
        }

        // Bridge Status Check
        function checkBridgeStatus() {
            const bridgeStatus = document.getElementById('bridge-status');
            let status = '<h3>Bridge Availability:</h3>';

            // Check Camera bridge
            if (window.CameraBridge) {
                status += '<div class="test-result success">âœ“ CameraBridge: Available</div>';

                // Test bridge methods
                const methods = ['enumerateDevices', 'getUserMedia', 'stopUserMedia', 'captureFrame', 'getCapabilities'];
                methods.forEach(method => {
                    if (typeof window.CameraBridge[method] === 'function') {
                        status += `<div class="test-result success">âœ“ CameraBridge.${method}: Available</div>`;
                    } else {
                        status += `<div class="test-result error">âœ— CameraBridge.${method}: Missing</div>`;
                    }
                });
            } else {
                status += '<div class="test-result error">âœ— CameraBridge: Not Available</div>';
            }

            // Check MediaDevices polyfill
            if (navigator.mediaDevices) {
                status += '<div class="test-result success">âœ“ navigator.mediaDevices: Available</div>';

                if (navigator.mediaDevices.getUserMedia) {
                    status += '<div class="test-result success">âœ“ getUserMedia: Available</div>';
                } else {
                    status += '<div class="test-result error">âœ— getUserMedia: Missing</div>';
                }

                if (navigator.mediaDevices.enumerateDevices) {
                    status += '<div class="test-result success">âœ“ enumerateDevices: Available</div>';
                } else {
                    status += '<div class="test-result error">âœ— enumerateDevices: Missing</div>';
                }
            } else {
                status += '<div class="test-result error">âœ— navigator.mediaDevices: Missing</div>';
            }

            // Check polyfill status
            if (window.SecureCamera && window.SecureCamera.isActive()) {
                status += '<div class="test-result success">âœ“ Camera Polyfill: Active</div>';
            } else {
                status += '<div class="test-result error">âœ— Camera Polyfill: Inactive</div>';
            }

            bridgeStatus.innerHTML = status;
        }

        // Initialize tests when page loads
        window.addEventListener('load', function() {
            console.log('Camera test page loaded - checking bridge status');
            checkBridgeStatus();

            // Auto-run basic tests
            setTimeout(() => {
                log('device', 'Auto-running device enumeration test...');
                testEnumerateDevices();
            }, 1000);
        });

        // Error handling
        window.addEventListener('error', function(e) {
            console.error('Page error:', e.error);
            log('system', `Page error: ${e.message}`, 'error');
        });

        // Handle permission changes
        if (navigator.permissions) {
            navigator.permissions.query({name: 'camera'}).then(function(permissionStatus) {
                log('system', `Camera permission: ${permissionStatus.state}`);

                permissionStatus.addEventListener('change', function() {
                    log('system', `Camera permission changed: ${this.state}`);
                });
            });
        }
    </script>
</body>
</html>